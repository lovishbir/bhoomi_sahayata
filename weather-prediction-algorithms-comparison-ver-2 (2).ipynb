{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1129180,"sourceType":"datasetVersion","datasetId":635203}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport math\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tqdm import tqdm\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import KFold\nfrom tabulate import tabulate\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\n\nWest_Bengal_Kolkata = '/kaggle/input/historical-weather-data-for-indian-cities/hyderabad.csv'\nKarnatka='/kaggle/input/historical-weather-data-for-indian-cities/bengaluru.csv'\nRajasthan='/kaggle/input/historical-weather-data-for-indian-cities/jaipur.csv'\nMaharashtra='/kaggle/input/historical-weather-data-for-indian-cities/pune.csv'\nUttar_Pardesh='/kaggle/input/historical-weather-data-for-indian-cities/kanpur.csv'\n\n\ndf = pd.read_csv(West_Bengal_Kolkata)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:02:29.355460Z","iopub.execute_input":"2024-08-01T11:02:29.355964Z","iopub.status.idle":"2024-08-01T11:02:45.265560Z","shell.execute_reply.started":"2024-08-01T11:02:29.355937Z","shell.execute_reply":"2024-08-01T11:02:45.264767Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install tabulate","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:03:12.199751Z","iopub.execute_input":"2024-08-01T11:03:12.200486Z","iopub.status.idle":"2024-08-01T11:03:25.580474Z","shell.execute_reply.started":"2024-08-01T11:03:12.200436Z","shell.execute_reply":"2024-08-01T11:03:25.579264Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (0.9.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:03:25.582525Z","iopub.execute_input":"2024-08-01T11:03:25.582898Z","iopub.status.idle":"2024-08-01T11:03:25.622126Z","shell.execute_reply.started":"2024-08-01T11:03:25.582869Z","shell.execute_reply":"2024-08-01T11:03:25.621235Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"             date_time  maxtempC  mintempC  totalSnow_cm  sunHour  uvIndex  \\\n0  2009-01-01 00:00:00        28        15           0.0      8.7        6   \n1  2009-01-01 01:00:00        28        15           0.0      8.7        6   \n2  2009-01-01 02:00:00        28        15           0.0      8.7        6   \n3  2009-01-01 03:00:00        28        15           0.0      8.7        6   \n4  2009-01-01 04:00:00        28        15           0.0      8.7        6   \n\n   uvIndex.1  moon_illumination  moonrise   moonset  ... WindChillC  \\\n0          1                 31  09:57 AM  09:58 PM  ...         21   \n1          1                 31  09:57 AM  09:58 PM  ...         20   \n2          1                 31  09:57 AM  09:58 PM  ...         20   \n3          1                 31  09:57 AM  09:58 PM  ...         19   \n4          1                 31  09:57 AM  09:58 PM  ...         21   \n\n  WindGustKmph  cloudcover  humidity  precipMM  pressure  tempC  visibility  \\\n0            9           0        83       0.0      1013     16          10   \n1            9           0        85       0.0      1013     16          10   \n2            8           0        86       0.0      1013     15          10   \n3            8           0        88       0.0      1013     15          10   \n4            7           0        80       0.0      1014     16          10   \n\n   winddirDegree  windspeedKmph  \n0            150              6  \n1            148              5  \n2            147              5  \n3            145              5  \n4            148              5  \n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>maxtempC</th>\n      <th>mintempC</th>\n      <th>totalSnow_cm</th>\n      <th>sunHour</th>\n      <th>uvIndex</th>\n      <th>uvIndex.1</th>\n      <th>moon_illumination</th>\n      <th>moonrise</th>\n      <th>moonset</th>\n      <th>...</th>\n      <th>WindChillC</th>\n      <th>WindGustKmph</th>\n      <th>cloudcover</th>\n      <th>humidity</th>\n      <th>precipMM</th>\n      <th>pressure</th>\n      <th>tempC</th>\n      <th>visibility</th>\n      <th>winddirDegree</th>\n      <th>windspeedKmph</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-01-01 00:00:00</td>\n      <td>28</td>\n      <td>15</td>\n      <td>0.0</td>\n      <td>8.7</td>\n      <td>6</td>\n      <td>1</td>\n      <td>31</td>\n      <td>09:57 AM</td>\n      <td>09:58 PM</td>\n      <td>...</td>\n      <td>21</td>\n      <td>9</td>\n      <td>0</td>\n      <td>83</td>\n      <td>0.0</td>\n      <td>1013</td>\n      <td>16</td>\n      <td>10</td>\n      <td>150</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-01-01 01:00:00</td>\n      <td>28</td>\n      <td>15</td>\n      <td>0.0</td>\n      <td>8.7</td>\n      <td>6</td>\n      <td>1</td>\n      <td>31</td>\n      <td>09:57 AM</td>\n      <td>09:58 PM</td>\n      <td>...</td>\n      <td>20</td>\n      <td>9</td>\n      <td>0</td>\n      <td>85</td>\n      <td>0.0</td>\n      <td>1013</td>\n      <td>16</td>\n      <td>10</td>\n      <td>148</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-01-01 02:00:00</td>\n      <td>28</td>\n      <td>15</td>\n      <td>0.0</td>\n      <td>8.7</td>\n      <td>6</td>\n      <td>1</td>\n      <td>31</td>\n      <td>09:57 AM</td>\n      <td>09:58 PM</td>\n      <td>...</td>\n      <td>20</td>\n      <td>8</td>\n      <td>0</td>\n      <td>86</td>\n      <td>0.0</td>\n      <td>1013</td>\n      <td>15</td>\n      <td>10</td>\n      <td>147</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-01-01 03:00:00</td>\n      <td>28</td>\n      <td>15</td>\n      <td>0.0</td>\n      <td>8.7</td>\n      <td>6</td>\n      <td>1</td>\n      <td>31</td>\n      <td>09:57 AM</td>\n      <td>09:58 PM</td>\n      <td>...</td>\n      <td>19</td>\n      <td>8</td>\n      <td>0</td>\n      <td>88</td>\n      <td>0.0</td>\n      <td>1013</td>\n      <td>15</td>\n      <td>10</td>\n      <td>145</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-01-01 04:00:00</td>\n      <td>28</td>\n      <td>15</td>\n      <td>0.0</td>\n      <td>8.7</td>\n      <td>6</td>\n      <td>1</td>\n      <td>31</td>\n      <td>09:57 AM</td>\n      <td>09:58 PM</td>\n      <td>...</td>\n      <td>21</td>\n      <td>7</td>\n      <td>0</td>\n      <td>80</td>\n      <td>0.0</td>\n      <td>1014</td>\n      <td>16</td>\n      <td>10</td>\n      <td>148</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"target_variable = 'maxtempC'\n\n\nX = df.drop(columns=[target_variable]).values \ny = df[target_variable].values  \n\ndate_column_index = np.where(X[0] == 'date_time')[0]\nif date_column_index.size > 0:\n    X = np.delete(X, date_column_index, axis=1)\n\nnon_numeric_cols = [col for col in range(X.shape[1]) if not np.issubdtype(X.dtype, np.number)]\nX[:, non_numeric_cols] = np.apply_along_axis(pd.to_numeric, 0, X[:, non_numeric_cols], errors='coerce')\n\n\nimputer = SimpleImputer(strategy='mean') \nX = imputer.fit_transform(X)\n\n\nnumerical_features = [col for col in range(X.shape[1]) if np.issubdtype(X.dtype, np.number)]\nscaler = StandardScaler()\nX[:, numerical_features] = scaler.fit_transform(X[:, numerical_features])\n\nmodel = RandomForestRegressor() \nrfe = RFE(model, n_features_to_select=10)  \nX_rfe = rfe.fit_transform(X, y)\n\n\nX_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:03:25.623208Z","iopub.execute_input":"2024-08-01T11:03:25.623472Z","iopub.status.idle":"2024-08-01T11:11:12.878494Z","shell.execute_reply.started":"2024-08-01T11:03:25.623443Z","shell.execute_reply":"2024-08-01T11:11:12.877629Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_rfe.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:11:12.880134Z","iopub.execute_input":"2024-08-01T11:11:12.880427Z","iopub.status.idle":"2024-08-01T11:11:12.886295Z","shell.execute_reply.started":"2024-08-01T11:11:12.880402Z","shell.execute_reply":"2024-08-01T11:11:12.885405Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(96432, 10)"},"metadata":{}}]},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n    layers.Dropout(0.2), \n    layers.Dense(64, activation='relu'),\n    layers.Dense(32, activation='relu'),\n    layers.Dense(1) \n\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n\nepochs = 100\n\n\nepoch_bar = tqdm(total=epochs, desc='Epochs', unit='epoch', position=0)\n\nfor epoch in range(epochs):\n    history = model.fit(X_train, y_train, epochs=1, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n\n   \n    mse = model.evaluate(X_test, y_test, verbose=0)\n\n    epoch_bar.set_postfix_str(f'Epoch {epoch + 1}/{epochs} - loss: {history.history[\"loss\"][0]:.4f} - val_loss: {history.history[\"val_loss\"][0]:.4f} - Test MSE: {mse:.4f}')\n    epoch_bar.update(1)\n\nepoch_bar.close()\n\npredictions = model.predict(X_test)\n\nresults = []\nfor i in range(10):\n    actual_value = y_test[i]\n    predicted_value = predictions[i][0]\n    results.append([f'Sample {i + 1}', f'{actual_value:.2f}', f'{predicted_value:.2f}'])\n\n\ntable = tabulate(results, headers=['Sample', 'Actual', 'Predicted'], tablefmt='pretty')\n\nprint(table)\n\nbackpropagation_mse = model.evaluate(X_test, y_test, verbose=0)\nprint(f'backpropagation Test MSE: {backpropagation_mse:.4f}')\n\nbackpropagation_mae = mean_absolute_error(y_test, predictions)\nprint(f'backpropagation Test MAE: {backpropagation_mae:.4f}')\n\n\nbackpropagation_rmse = math.sqrt(backpropagation_mse)\nprint(f'backpropagation Test RMSE: {backpropagation_rmse:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:11:12.887582Z","iopub.execute_input":"2024-08-01T11:11:12.888156Z","iopub.status.idle":"2024-08-01T11:22:28.551697Z","shell.execute_reply.started":"2024-08-01T11:11:12.888124Z","shell.execute_reply":"2024-08-01T11:22:28.550746Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [11:12<00:00,  6.72s/epoch, Epoch 100/100 - loss: 1.3816 - val_loss: 1.5199 - Test MSE: 1.4795]","output_type":"stream"},{"name":"stdout","text":" 39/603 [>.............................] - ETA: 0s ","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"603/603 [==============================] - 1s 1ms/step\n+-----------+--------+-----------+\n|  Sample   | Actual | Predicted |\n+-----------+--------+-----------+\n| Sample 1  | 28.00  |   29.13   |\n| Sample 2  | 23.00  |   25.98   |\n| Sample 3  | 36.00  |   36.27   |\n| Sample 4  | 32.00  |   31.31   |\n| Sample 5  | 32.00  |   31.88   |\n| Sample 6  | 29.00  |   28.63   |\n| Sample 7  | 33.00  |   32.23   |\n| Sample 8  | 29.00  |   27.65   |\n| Sample 9  | 35.00  |   35.97   |\n| Sample 10 | 28.00  |   28.47   |\n+-----------+--------+-----------+\nbackpropagation Test MSE: 1.4795\nbackpropagation Test MAE: 0.9168\nbackpropagation Test RMSE: 1.2164\n","output_type":"stream"}]},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.LSTM(128, activation='relu', input_shape=(X_train.shape[1], 1)),\n    layers.Dropout(0.2),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(32, activation='relu'),\n    layers.Dense(1)\n])\n\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n\nepochs = 100\n\nepoch_bar = tqdm(total=epochs, desc='Epochs', unit='epoch', position=0)\n\nfor epoch in range(epochs):\n    history = model.fit(X_train, y_train, epochs=1, batch_size=32, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n\n    mse = model.evaluate(X_test, y_test, verbose=0)\n\n    epoch_bar.set_postfix_str(f'Epoch {epoch + 1}/{epochs} - loss: {history.history[\"loss\"][0]:.4f} - val_loss: {history.history[\"val_loss\"][0]:.4f} - Test MSE: {mse:.4f}')\n    epoch_bar.update(1)\n\n\nepoch_bar.close()\n\npredictions = model.predict(X_test)\n\nresults = []\nfor i in range(10):\n    actual_value = y_test[i]\n    predicted_value = predictions[i][0]\n    results.append([f'Sample {i + 1}', f'{actual_value:.2f}', f'{predicted_value:.2f}'])\n\ntable = tabulate(results, headers=['Sample', 'Actual', 'Predicted'], tablefmt='pretty')\n\nprint(table)\n\n\nLSTM_mse = model.evaluate(X_test, y_test, verbose=0)\nprint(f'LSTM Test MSE: {LSTM_mse:.4f}')\n\nLSTM_mae = mean_absolute_error(y_test, predictions)\nprint(f'LSTM Test MAE: {LSTM_mae:.4f}')\n\n\nLSTM_rmse = math.sqrt(LSTM_mse)\nprint(f'LSTM Test RMSE: {LSTM_rmse:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:27:13.957231Z","iopub.execute_input":"2024-08-01T11:27:13.957966Z","iopub.status.idle":"2024-08-01T12:23:52.744208Z","shell.execute_reply.started":"2024-08-01T11:27:13.957933Z","shell.execute_reply":"2024-08-01T12:23:52.743454Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [56:34<00:00, 33.95s/epoch, Epoch 100/100 - loss: 0.5711 - val_loss: 0.8729 - Test MSE: 0.8751]\n","output_type":"stream"},{"name":"stdout","text":"603/603 [==============================] - 2s 3ms/step\n+-----------+--------+-----------+\n|  Sample   | Actual | Predicted |\n+-----------+--------+-----------+\n| Sample 1  | 28.00  |   28.93   |\n| Sample 2  | 23.00  |   23.13   |\n| Sample 3  | 36.00  |   35.26   |\n| Sample 4  | 32.00  |   31.83   |\n| Sample 5  | 32.00  |   32.68   |\n| Sample 6  | 29.00  |   28.69   |\n| Sample 7  | 33.00  |   32.22   |\n| Sample 8  | 29.00  |   28.46   |\n| Sample 9  | 35.00  |   35.46   |\n| Sample 10 | 28.00  |   28.03   |\n+-----------+--------+-----------+\nLSTM Test MSE: 0.8751\nLSTM Test MAE: 0.6938\nLSTM Test RMSE: 0.9355\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ntree_model = DecisionTreeRegressor(random_state=42)\ntree_model.fit(X_train, y_train)\n\ntree_predictions = tree_model.predict(X_test)\n\nDecision_tree_mse = mean_squared_error(y_test, tree_predictions)\n\ndef assign_zone(temperature):\n    red_zone_min = 35  \n    red_zone_max = 40  \n    orange_zone_min = 25  # Minimum temperature for orange zone\n    orange_zone_max = 30  # Maximum temperature for orange zone\n    green_zone_min = 20\n    green_zone_max = 25\n    yellow_zone_min = 20  # Minimum temperature for yellow zone\n    yellow_zone_max = 30  # Maximum temperature for yellow zone\n    \n    if red_zone_min <= temperature <= red_zone_max:\n        return 'Red'\n    elif orange_zone_min <= temperature <= orange_zone_max:\n        return 'Orange'\n    elif green_zone_min <= temperature <= green_zone_max:\n        return 'Green'\n    elif yellow_zone_min <= temperature <= yellow_zone_max:\n        return 'Yellow'\n    else:\n        return 'Unknown'\n\n# Create a list to store results with zones\ntree_results_with_zones = []\nfor i in range(10):\n    actual_value = y_test[i]\n    predicted_value = tree_predictions[i]\n    zone = assign_zone(predicted_value)  # Assign zone based on predicted temperature\n    tree_results_with_zones.append([f'Sample {i + 1}', f'{actual_value:.2f}', f'{predicted_value:.2f}', zone])\n\n# Generate a table with zones included\ntree_table_with_zones = tabulate(tree_results_with_zones, headers=['Sample', 'Actual', 'Predicted', 'Zone'], tablefmt='pretty')\n\n# Print the table with zones\nprint(\"Decision Tree Results with Zones:\")\nprint(tree_table_with_zones)\n\n# Calculate and display other metrics\nprint(f'Decision Tree Test MSE: {Decision_tree_mse:.4f}')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:00:17.040083Z","iopub.execute_input":"2024-08-01T13:00:17.040949Z","iopub.status.idle":"2024-08-01T13:00:17.475914Z","shell.execute_reply.started":"2024-08-01T13:00:17.040918Z","shell.execute_reply":"2024-08-01T13:00:17.474989Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Decision Tree Results with Zones:\n+-----------+--------+-----------+---------+\n|  Sample   | Actual | Predicted |  Zone   |\n+-----------+--------+-----------+---------+\n| Sample 1  | 28.00  |   28.00   | Orange  |\n| Sample 2  | 23.00  |   23.00   |  Green  |\n| Sample 3  | 36.00  |   36.00   |   Red   |\n| Sample 4  | 32.00  |   32.00   | Unknown |\n| Sample 5  | 32.00  |   32.00   | Unknown |\n| Sample 6  | 29.00  |   29.00   | Orange  |\n| Sample 7  | 33.00  |   33.00   | Unknown |\n| Sample 8  | 29.00  |   28.00   | Orange  |\n| Sample 9  | 35.00  |   36.00   |   Red   |\n| Sample 10 | 28.00  |   28.00   | Orange  |\n+-----------+--------+-----------+---------+\nDecision Tree Test MSE: 0.9329\n","output_type":"stream"}]},{"cell_type":"code","source":"# Standardize the data using StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Create and train the SVM regression model\nsvm_model = SVR(kernel='rbf')  # You can try different kernels such as 'linear', 'poly', or 'sigmoid'\nsvm_model.fit(X_train_scaled, y_train)\n\n# Make predictions on the test set\nsvm_predictions = svm_model.predict(X_test_scaled)\n\n# Calculate MSE for the SVM model\nsvm_mse = mean_squared_error(y_test, svm_predictions)\ndef assign_zone(temperature):\n    red_zone_min = 35  \n    red_zone_max = 40  \n    orange_zone_min = 25  # Minimum temperature for orange zone\n    orange_zone_max = 30  # Maximum temperature for orange zone\n    green_zone_min = 20\n    green_zone_max = 25\n    yellow_zone_min = 20  # Minimum temperature for yellow zone\n    yellow_zone_max = 30  # Maximum temperature for yellow zone\n    \n    if red_zone_min <= temperature <= red_zone_max:\n        return 'Red'\n    elif orange_zone_min <= temperature <= orange_zone_max:\n        return 'Orange'\n    elif green_zone_min <= temperature <= green_zone_max:\n        return 'Green'\n    elif yellow_zone_min <= temperature <= yellow_zone_max:\n        return 'Yellow'\n    else:\n        return 'Unknown'\n# Store results in a list\nsvm_results_with_zones = []\nfor i in range(10):\n    actual_value = y_test[i]\n    zone = assign_zone(predicted_value)\n    predicted_value = svm_predictions[i]\n    svm_results_with_zones.append([f'Sample {i + 1}', f'{actual_value:.2f}', f'{predicted_value:.2f}',zone])\n\n# Create a table for SVM results\nsvm_table_with_zones = tabulate(svm_results_with_zones, headers=['Sample', 'Actual', 'Predicted','Zone'], tablefmt='pretty')\n\n# Print the SVM results table\nprint(\"SVM Results with zones:\")\nprint(svm_table_with_zones)\n\n# Print the MSE for the SVM\nprint(f'SVM Test MSE: {svm_mse:.4f}')\n\n# Calculate MAE and Print the MAE\nsvm_mae = mean_absolute_error(y_test, svm_predictions)\nprint(f'svm Test MAE: {svm_mae:.4f}')\n\n# Calculate and Print the RMSE\nsvm_rmse = math.sqrt(svm_mse)\nprint(f'svm Test RMSE: {svm_rmse:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:26:08.140537Z","iopub.execute_input":"2024-08-01T14:26:08.141222Z","iopub.status.idle":"2024-08-01T14:31:09.416351Z","shell.execute_reply.started":"2024-08-01T14:26:08.141169Z","shell.execute_reply":"2024-08-01T14:31:09.415217Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"SVM Results with zones:\n+-----------+--------+-----------+---------+\n|  Sample   | Actual | Predicted |  Zone   |\n+-----------+--------+-----------+---------+\n| Sample 1  | 28.00  |   28.83   | Orange  |\n| Sample 2  | 23.00  |   24.81   | Orange  |\n| Sample 3  | 36.00  |   37.39   |  Green  |\n| Sample 4  | 32.00  |   30.61   |   Red   |\n| Sample 5  | 32.00  |   32.11   | Unknown |\n| Sample 6  | 29.00  |   28.45   | Unknown |\n| Sample 7  | 33.00  |   33.07   | Orange  |\n| Sample 8  | 29.00  |   26.85   | Unknown |\n| Sample 9  | 35.00  |   36.82   | Orange  |\n| Sample 10 | 28.00  |   27.66   |   Red   |\n+-----------+--------+-----------+---------+\nSVM Test MSE: 1.6350\nsvm Test MAE: 0.9488\nsvm Test RMSE: 1.2787\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create and train the XGBoost regression model\nxgb_model = XGBRegressor(objective='reg:squarederror')  # 'reg:squarederror' for regression\nxgb_model.fit(X_train, y_train)\n\n# Make predictions on the test set\nxgb_predictions = xgb_model.predict(X_test)\n\n# Calculate MSE for the XGBoost model\nxgb_mse = mean_squared_error(y_test, xgb_predictions)\ndef assign_zone(temperature):\n    red_zone_min = 35  \n    red_zone_max = 40  \n    orange_zone_min = 25  # Minimum temperature for orange zone\n    orange_zone_max = 30  # Maximum temperature for orange zone\n    green_zone_min = 20\n    green_zone_max = 25\n    yellow_zone_min = 20  # Minimum temperature for yellow zone\n    yellow_zone_max = 30  # Maximum temperature for yellow zone\n    \n    if red_zone_min <= temperature <= red_zone_max:\n        return 'Red'\n    elif orange_zone_min <= temperature <= orange_zone_max:\n        return 'Orange'\n    elif green_zone_min <= temperature <= green_zone_max:\n        return 'Green'\n    elif yellow_zone_min <= temperature <= yellow_zone_max:\n        return 'Yellow'\n    else:\n        return 'Unknown'\n# Store results in a list\nxgb_results_with_zones = []\nfor i in range(10):\n    actual_value = y_test[i]\n    predicted_value = xgb_predictions[i]\n    xgb_results_with_zones.append([f'Sample {i + 1}', f'{actual_value:.2f}', f'{predicted_value:.2f}',zone])\n\n# Create a table for XGBoost results\nxgb_table_with_zones = tabulate(xgb_results_with_zones, headers=['Sample', 'Actual', 'Predicted','Zones'], tablefmt='pretty')\n\n# Print the XGBoost results table\nprint(\"XGBoost Results:\")\nprint(xgb_table_with_zones)\n\n# Print the MSE for XGBoost\nprint(f'XGBoost Test MSE: {xgb_mse:.4f}')\n\n# Calculate MAE and Print the MAE\nxgb_mae = mean_absolute_error(y_test, xgb_predictions)\nprint(f'XGBoost Test MAE: {xgb_mae:.4f}')\n\n# Calculate and Print the RMSE\nxgb_rmse = math.sqrt(xgb_mse)\nprint(f'XGBoost Test RMSE: {xgb_rmse:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:52:50.197176Z","iopub.execute_input":"2024-08-01T14:52:50.197565Z","iopub.status.idle":"2024-08-01T14:52:50.593990Z","shell.execute_reply.started":"2024-08-01T14:52:50.197537Z","shell.execute_reply":"2024-08-01T14:52:50.593249Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"XGBoost Results:\n+-----------+--------+-----------+-------+\n|  Sample   | Actual | Predicted | Zones |\n+-----------+--------+-----------+-------+\n| Sample 1  | 28.00  |   28.29   |  Red  |\n| Sample 2  | 23.00  |   24.33   |  Red  |\n| Sample 3  | 36.00  |   37.36   |  Red  |\n| Sample 4  | 32.00  |   31.07   |  Red  |\n| Sample 5  | 32.00  |   32.01   |  Red  |\n| Sample 6  | 29.00  |   28.52   |  Red  |\n| Sample 7  | 33.00  |   32.68   |  Red  |\n| Sample 8  | 29.00  |   29.16   |  Red  |\n| Sample 9  | 35.00  |   36.22   |  Red  |\n| Sample 10 | 28.00  |   27.55   |  Red  |\n+-----------+--------+-----------+-------+\nXGBoost Test MSE: 1.0750\nXGBoost Test MAE: 0.7836\nXGBoost Test RMSE: 1.0368\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create and train the CatBoost regression model\ncatboost_model = CatBoostRegressor(iterations=500, depth=10, learning_rate=0.05, loss_function='RMSE')\ncatboost_model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=20, verbose=50)\n\n# Make predictions on the test set\ncatboost_predictions = catboost_model.predict(X_test)\n\n# Calculate MSE for the CatBoost model\ncatboost_mse = mean_squared_error(y_test, catboost_predictions)\ndef assign_zone(temperature):\n    red_zone_min = 35  \n    red_zone_max = 40  \n    orange_zone_min = 25  # Minimum temperature for orange zone\n    orange_zone_max = 30  # Maximum temperature for orange zone\n    green_zone_min = 20\n    green_zone_max = 25\n    yellow_zone_min = 20  # Minimum temperature for yellow zone\n    yellow_zone_max = 30  # Maximum temperature for yellow zone\n    \n    if red_zone_min <= temperature <= red_zone_max:\n        return 'Red'\n    elif orange_zone_min <= temperature <= orange_zone_max:\n        return 'Orange'\n    elif green_zone_min <= temperature <= green_zone_max:\n        return 'Green'\n    elif yellow_zone_min <= temperature <= yellow_zone_max:\n        return 'Yellow'\n    else:\n        return 'Unknown'\n# Store results in a list\ncatboost_results_with_zones = []\nfor i in range(10):\n    actual_value = y_test[i]\n    predicted_value = catboost_predictions[i]\n    catboost_results_with_zones.append([f'Sample {i + 1}', f'{actual_value:.2f}', f'{predicted_value:.2f}',zone])\n\n# Create a table for CatBoost results\ncatboost_table_with_zones = tabulate(catboost_results_with_zones, headers=['Sample', 'Actual', 'Predicted','Zones'], tablefmt='pretty')\n\n# Print the CatBoost results table\nprint(\"CatBoost Results:\")\nprint(catboost_table_with_zones)\n\n# Print the MSE for CatBoost\nprint(f'CatBoost Test MSE: {catboost_mse:.4f}')\n\n# Calculate MAE and Print the MAE\ncatboost_mae = mean_absolute_error(y_test, catboost_predictions)\nprint(f'CatBoost Test MAE: {catboost_mae:.4f}')\n\n# Calculate and Print the RMSE\ncatboost_rmse = math.sqrt(catboost_mse)\nprint(f'CatBoost Test RMSE: {catboost_rmse:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:53:27.447948Z","iopub.execute_input":"2024-08-01T14:53:27.448306Z","iopub.status.idle":"2024-08-01T14:53:39.268748Z","shell.execute_reply.started":"2024-08-01T14:53:27.448276Z","shell.execute_reply":"2024-08-01T14:53:39.267788Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"0:\tlearn: 4.2755126\ttest: 4.2821550\tbest: 4.2821550 (0)\ttotal: 22.7ms\tremaining: 11.3s\n50:\tlearn: 1.4530577\ttest: 1.4566424\tbest: 1.4566424 (50)\ttotal: 1.1s\tremaining: 9.72s\n100:\tlearn: 1.3087988\ttest: 1.3159632\tbest: 1.3159632 (100)\ttotal: 2.18s\tremaining: 8.6s\n150:\tlearn: 1.2450193\ttest: 1.2562964\tbest: 1.2562964 (150)\ttotal: 3.25s\tremaining: 7.51s\n200:\tlearn: 1.1933513\ttest: 1.2086451\tbest: 1.2086451 (200)\ttotal: 4.32s\tremaining: 6.43s\n250:\tlearn: 1.1501396\ttest: 1.1697984\tbest: 1.1697984 (250)\ttotal: 5.39s\tremaining: 5.34s\n300:\tlearn: 1.1112564\ttest: 1.1360061\tbest: 1.1360061 (300)\ttotal: 6.69s\tremaining: 4.42s\n350:\tlearn: 1.0776650\ttest: 1.1074343\tbest: 1.1074343 (350)\ttotal: 7.84s\tremaining: 3.33s\n400:\tlearn: 1.0470723\ttest: 1.0808461\tbest: 1.0808461 (400)\ttotal: 8.97s\tremaining: 2.21s\n450:\tlearn: 1.0187890\ttest: 1.0567636\tbest: 1.0567636 (450)\ttotal: 10s\tremaining: 1.09s\n499:\tlearn: 0.9931974\ttest: 1.0345271\tbest: 1.0345271 (499)\ttotal: 11s\tremaining: 0us\n\nbestTest = 1.034527082\nbestIteration = 499\n\nCatBoost Results:\n+-----------+--------+-----------+-------+\n|  Sample   | Actual | Predicted | Zones |\n+-----------+--------+-----------+-------+\n| Sample 1  | 28.00  |   28.63   |  Red  |\n| Sample 2  | 23.00  |   24.22   |  Red  |\n| Sample 3  | 36.00  |   37.10   |  Red  |\n| Sample 4  | 32.00  |   30.73   |  Red  |\n| Sample 5  | 32.00  |   32.01   |  Red  |\n| Sample 6  | 29.00  |   28.44   |  Red  |\n| Sample 7  | 33.00  |   32.75   |  Red  |\n| Sample 8  | 29.00  |   28.02   |  Red  |\n| Sample 9  | 35.00  |   36.64   |  Red  |\n| Sample 10 | 28.00  |   27.33   |  Red  |\n+-----------+--------+-----------+-------+\nCatBoost Test MSE: 1.0702\nCatBoost Test MAE: 0.7853\nCatBoost Test RMSE: 1.0345\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create and train the Linear Regression model\nlinear_model = LinearRegression()\nlinear_model.fit(X_train, y_train)\n\n# Make predictions on the test set\nlinear_predictions = linear_model.predict(X_test)\n\n# Calculate MSE for the Linear Regression model\nlinear_mse = mean_squared_error(y_test, linear_predictions)\ndef assign_zone(temperature):\n    red_zone_min = 35  \n    red_zone_max = 40  \n    orange_zone_min = 25  # Minimum temperature for orange zone\n    orange_zone_max = 30  # Maximum temperature for orange zone\n    green_zone_min = 20\n    green_zone_max = 25\n    yellow_zone_min = 20  # Minimum temperature for yellow zone\n    yellow_zone_max = 30  # Maximum temperature for yellow zone\n    \n    if red_zone_min <= temperature <= red_zone_max:\n        return 'Red'\n    elif orange_zone_min <= temperature <= orange_zone_max:\n        return 'Orange'\n    elif green_zone_min <= temperature <= green_zone_max:\n        return 'Green'\n    elif yellow_zone_min <= temperature <= yellow_zone_max:\n        return 'Yellow'\n    else:\n        return 'Unknown'\n# Store results in a list\nlinear_results_with_zones = []\nfor i in range(10):\n    actual_value = y_test[i]\n    predicted_value = linear_predictions[i]\n    linear_results_with_zones.append([f'Sample {i + 1}', f'{actual_value:.2f}', f'{predicted_value:.2f}',zone])\n\n# Create a table for Linear Regression results\nlinear_table_with_zones = tabulate(linear_results_with_zones, headers=['Sample', 'Actual', 'Predicted','Zones'], tablefmt='pretty')\n\n# Print the Linear Regression results table\nprint(\"Linear Regression Results:\")\nprint(linear_table_with_zones)\n\n# Print the MSE for Linear Regression\nprint(f'Linear Regression Test MSE: {linear_mse:.4f}')\n\n# Calculate MAE and Print the MAE\nlinear_mae = mean_absolute_error(y_test, linear_predictions)\nprint(f'Linear Regression Test MAE: {linear_mae:.4f}')\n\n# Calculate and Print the RMSE\nlinear_rmse = math.sqrt(linear_mse)\nprint(f'Linear Regression Test RMSE: {linear_rmse:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:54:21.619014Z","iopub.execute_input":"2024-08-01T14:54:21.619621Z","iopub.status.idle":"2024-08-01T14:54:21.723502Z","shell.execute_reply.started":"2024-08-01T14:54:21.619588Z","shell.execute_reply":"2024-08-01T14:54:21.721800Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Linear Regression Results:\n+-----------+--------+-----------+-------+\n|  Sample   | Actual | Predicted | Zones |\n+-----------+--------+-----------+-------+\n| Sample 1  | 28.00  |   29.33   |  Red  |\n| Sample 2  | 23.00  |   22.78   |  Red  |\n| Sample 3  | 36.00  |   37.34   |  Red  |\n| Sample 4  | 32.00  |   31.12   |  Red  |\n| Sample 5  | 32.00  |   32.74   |  Red  |\n| Sample 6  | 29.00  |   29.56   |  Red  |\n| Sample 7  | 33.00  |   33.45   |  Red  |\n| Sample 8  | 29.00  |   25.83   |  Red  |\n| Sample 9  | 35.00  |   37.81   |  Red  |\n| Sample 10 | 28.00  |   26.45   |  Red  |\n+-----------+--------+-----------+-------+\nLinear Regression Test MSE: 2.8482\nLinear Regression Test MAE: 1.3280\nLinear Regression Test RMSE: 1.6877\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming X and y are your features and target variable as NumPy arrays\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n    # Initialize and train your model\n    model = RandomForestRegressor(n_estimators=100, random_state=42)\n    model.fit(X_train, y_train)\n\n    # Make predictions on the test set\n    y_pred = model.predict(X_test)\n\n    # Evaluate the model\n    mse = mean_squared_error(y_test, y_pred)\n    #print(f'Mean Squared Error: {mse}')\n\n# After the loop, you can choose to train the final model on the entire dataset for submission\nfinal_model = RandomForestRegressor(n_estimators=100, random_state=42)\nfinal_model.fit(X, y)\n\n# Make predictions on new data (if applicable)\nnew_data_predictions = final_model.predict(X_train)\n\n# Make predictions on the entire dataset using the final model\ny_pred_final = final_model.predict(X)\n\n# Assuming y and y_pred_final are NumPy arrays or pandas Series\nactual_predicted_table = pd.DataFrame({\n    'Actual_Value': y,\n    'Predicted_Value': y_pred_final\n})\n\n# Display the table\nprint(actual_predicted_table)\n\n# Calculate the Mean Squared Error\nkfold_mse = mean_squared_error(y, y_pred_final)\nprint(f'Kfold Test MSE: {kfold_mse:.4f}')\n\n# Calculate Mean Absolute Error\nkfold_mae = mean_absolute_error(y, y_pred_final)\nprint(f'Kfold Test MAE: {kfold_mae:.4f}')\n\n# Calculate and Print the RMSE\nkfold_rmse = math.sqrt(kfold_mse)\nprint(f'Kfold Test RMSE: {kfold_rmse:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:54:26.281683Z","iopub.execute_input":"2024-08-01T14:54:26.282064Z","iopub.status.idle":"2024-08-01T14:59:00.124163Z","shell.execute_reply.started":"2024-08-01T14:54:26.282023Z","shell.execute_reply":"2024-08-01T14:59:00.123260Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"       Actual_Value  Predicted_Value\n0                28            27.97\n1                28            28.00\n2                28            28.01\n3                28            28.02\n4                28            28.03\n...             ...              ...\n96427            26            25.92\n96428            26            25.94\n96429            26            25.94\n96430            26            25.92\n96431            26            25.95\n\n[96432 rows x 2 columns]\nKfold Test MSE: 0.0487\nKfold Test MAE: 0.1333\nKfold Test RMSE: 0.2207\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}